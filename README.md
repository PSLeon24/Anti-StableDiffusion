# Deepfake-Shield
### Objective
The goal of this project is to advance our research on disrupting deepfakes to a level where it can be presented at ICML 2025. This project aims to develop effective techniques that can interfere with the creation or dissemination of deepfake content, rendering it unusable or easily identifiable as manipulated.

![image](https://github.com/user-attachments/assets/4a83d5c5-6371-42e5-90c0-5774edbb7c9a)

### Abstract
Deepfake-Shield is a system designed to counter deepfake technology by introducing methods that actively disrupt the deepfake generation process or degrade the quality of deepfakes to make them less convincing. By leveraging adversarial techniques, noise injection, and data manipulation, this project provides a proactive approach to mitigating the risks posed by deepfake technology.

### Result

### Environment Setup

Pretrained checkpoints of different Stable Diffusion versions can be downloaded from provided links in the table below:
|Version|Link|
|:--:|:--:|
|2.1|<a href="https://huggingface.co/stabilityai/stable-diffusion-2-1-base">stable-diffusion-2-1-base</a>|
|1.5|<a href="#">To be added</a>|
|1.4|<a href="https://huggingface.co/CompVis/stable-diffusion-v1-4">stable-diffusion-v1-4</a>|

### Usage
#### Clone this repository and Install dependencies
1. Clone the repository: ```git clone https://github.com/yourusername/Deepfake-Shield.git``` 
2. Install dependencies: ```pip install -r requirements.txt```

#### Dataset Preparation


### Citation

```
@inproceedings{Citation Key,
  title={Deepfake-Shield},
  author={Yeong-Min Ko},
  booktitle={to be added.},
  year={2025}
}
```

---

## 1. Requirements Analysis

## 2. Design
![mysystem](https://github.com/user-attachments/assets/f6badce7-0d82-4db8-9dd3-3b01919321d8)

## 3. Implementation
## 4. Testing
## 5. Maintenance

### References
