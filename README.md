# Deepfake-Shield
### Objective
The goal of this project is to advance our research on disrupting deepfakes to a level where it can be presented at CVPR 2025. This project aims to develop effective techniques that can interfere with the creation or dissemination of deepfake content, rendering it unusable or easily identifiable as manipulated.

![image](https://github.com/user-attachments/assets/4a83d5c5-6371-42e5-90c0-5774edbb7c9a)

### Description
Deepfake-Shield is a system designed to counter deepfake technology by introducing methods that actively disrupt the deepfake generation process or degrade the quality of deepfakes to make them less convincing. By leveraging adversarial techniques, noise injection, and data manipulation, this project provides a proactive approach to mitigating the risks posed by deepfake technology.

### Introduction
Deepfakes pose a significant threat by generating realistic but fake media that can deceive viewers and systems. Instead of merely detecting deepfakes after they are created, Deepfake-Shield takes a more proactive approach by disrupting the deepfake generation process. This disruption makes it challenging for attackers to create convincing deepfakes, thereby reducing the potential harm.

### Result

### Citation

```
@inproceedings{Citation Key,
  title={Deepfake-Shield},
  author={Yeong-Min Ko},
  booktitle={to be added.},
  year={2025}
}
```

### Dependencies

### Usage
1. Clone the repository: ```git clone https://github.com/yourusername/Deepfake-Shield.git``` 
2. Install dependencies: ```pip install -r requirements.txt```

### Notes

---

## 1. Requirements Analysis

## 2. Design
![mysystem](https://github.com/user-attachments/assets/f6badce7-0d82-4db8-9dd3-3b01919321d8)

## 3. Implementation
## 4. Testing
## 5. Maintenance

### References
